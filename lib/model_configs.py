MODELS = {
    'llama2': {
        'model_path': 'meta-llama/Llama-2-7b-chat-hf',
        'tokenizer_path': 'meta-llama/Llama-2-7b-chat-hf',
        'conversation_template': 'llama-2'
    },
        'vicuna': {
        'model_path': 'lmsys/vicuna-7b-v1.5',
        'tokenizer_path': 'lmsys/vicuna-7b-v1.5',
        'conversation_template': 'vicuna'
    },
}